{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMDjX/37zjBf7aLuiOA1s9V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/code-1-mukul/Deep-Learning-Lab/blob/main/DL_LAB_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup and Load dataset"
      ],
      "metadata": {
        "id": "LkpE4Wjrm-lV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVYVTXzGmzFY",
        "outputId": "17883130-7d5c-45e8-bdc9-20e20a91145a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(-1, 784).astype(np.float32)\n",
        "X_test  = X_test.reshape(-1, 784).astype(np.float32)\n",
        "\n",
        "X_train /= 255.0\n",
        "X_test  /= 255.0\n",
        "\n",
        "def one_hot(y, num_classes=10):\n",
        "    oh = np.zeros((y.shape[0], num_classes))\n",
        "    oh[np.arange(y.shape[0]), y] = 1\n",
        "    return oh\n",
        "\n",
        "Y_train = one_hot(y_train, 10)\n",
        "Y_test  = one_hot(y_test, 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Activation & Loss"
      ],
      "metadata": {
        "id": "DLPioF4AnQXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def relu(z):\n",
        "    return np.maximum(0, z)\n",
        "\n",
        "def relu_deriv(z):\n",
        "    return (z > 0).astype(np.float32)\n",
        "\n",
        "def softmax(z):\n",
        "    z = z - np.max(z, axis=1, keepdims=True)  # stability\n",
        "    exp = np.exp(z)\n",
        "    return exp / np.sum(exp, axis=1, keepdims=True)\n",
        "\n",
        "def cross_entropy(y_true, y_pred):\n",
        "    eps = 1e-9\n",
        "    return -np.mean(np.sum(y_true * np.log(y_pred + eps), axis=1))\n"
      ],
      "metadata": {
        "id": "6fzM-KyqnFAf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi Layer Perceptron"
      ],
      "metadata": {
        "id": "AkbdsuiPna4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP:\n",
        "    def __init__(self, in_dim=784, h1=128, h2=64, out_dim=10, lr=0.01):\n",
        "        self.lr = lr\n",
        "        self.W1 = 0.01 * np.random.randn(in_dim, h1)\n",
        "        self.b1 = np.zeros((1, h1))\n",
        "        self.W2 = 0.01 * np.random.randn(h1, h2)\n",
        "        self.b2 = np.zeros((1, h2))\n",
        "        self.W3 = 0.01 * np.random.randn(h2, out_dim)\n",
        "        self.b3 = np.zeros((1, out_dim))\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.Z1 = X @ self.W1 + self.b1      # (B,128)\n",
        "        self.A1 = relu(self.Z1)\n",
        "        self.Z2 = self.A1 @ self.W2 + self.b2  # (B,64)\n",
        "        self.A2 = relu(self.Z2)\n",
        "        self.Z3 = self.A2 @ self.W3 + self.b3  # (B,10)\n",
        "        self.Yhat = softmax(self.Z3)\n",
        "        return self.Yhat\n",
        "\n",
        "    def backward(self, X, Y):\n",
        "        B = X.shape[0]\n",
        "\n",
        "        dZ3 = (self.Yhat - Y) / B\n",
        "        dW3 = self.A2.T @ dZ3\n",
        "        db3 = np.sum(dZ3, axis=0, keepdims=True)\n",
        "\n",
        "        dA2 = dZ3 @ self.W3.T\n",
        "        dZ2 = dA2 * relu_deriv(self.Z2)\n",
        "        dW2 = self.A1.T @ dZ2\n",
        "        db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
        "\n",
        "        dA1 = dZ2 @ self.W2.T\n",
        "        dZ1 = dA1 * relu_deriv(self.Z1)\n",
        "        dW1 = X.T @ dZ1\n",
        "        db1 = np.sum(dZ1, axis=0, keepdims=True)\n",
        "\n",
        "        self.W3 -= self.lr * dW3; self.b3 -= self.lr * db3\n",
        "        self.W2 -= self.lr * dW2; self.b2 -= self.lr * db2\n",
        "        self.W1 -= self.lr * dW1; self.b1 -= self.lr * db1\n",
        "\n",
        "    def fit(self, X, Y, epochs=10, batch_size=64):\n",
        "        n = X.shape[0]\n",
        "        for ep in range(epochs):\n",
        "            idx = np.random.permutation(n)\n",
        "            Xs, Ys = X[idx], Y[idx]\n",
        "            for i in range(0, n, batch_size):\n",
        "                xb = Xs[i:i+batch_size]\n",
        "                yb = Ys[i:i+batch_size]\n",
        "                self.forward(xb)\n",
        "                self.backward(xb, yb)\n",
        "\n",
        "            preds = self.forward(X)\n",
        "            loss = cross_entropy(Y, preds)\n",
        "            acc = np.mean(np.argmax(preds,1) == np.argmax(Y,1))\n",
        "            print(f\"Epoch {ep+1:02d} | loss={loss:.4f} | acc={acc:.4f}\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.argmax(self.forward(X), axis=1)\n"
      ],
      "metadata": {
        "id": "ZFgyqnpenY8j"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train & Evaluate"
      ],
      "metadata": {
        "id": "T-mZEOOinpGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp = MLP(lr=0.01)\n",
        "mlp.fit(X_train, Y_train, epochs=15, batch_size=128)\n",
        "\n",
        "test_preds = mlp.predict(X_test)\n",
        "test_acc = np.mean(test_preds == y_test)\n",
        "print(\"Test accuracy:\", test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0bHWkkanmyj",
        "outputId": "3bcdcd5b-80fc-459e-ecfd-e093e3483787"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | loss=2.3014 | acc=0.1124\n",
            "Epoch 02 | loss=2.3006 | acc=0.1124\n",
            "Epoch 03 | loss=2.2997 | acc=0.1124\n",
            "Epoch 04 | loss=2.2977 | acc=0.1124\n",
            "Epoch 05 | loss=2.2907 | acc=0.1380\n",
            "Epoch 06 | loss=2.2368 | acc=0.2306\n",
            "Epoch 07 | loss=2.0075 | acc=0.3186\n",
            "Epoch 08 | loss=1.3948 | acc=0.5189\n",
            "Epoch 09 | loss=1.0589 | acc=0.6544\n",
            "Epoch 10 | loss=0.8133 | acc=0.7395\n",
            "Epoch 11 | loss=0.7025 | acc=0.7732\n",
            "Epoch 12 | loss=0.6410 | acc=0.8016\n",
            "Epoch 13 | loss=0.5955 | acc=0.8217\n",
            "Epoch 14 | loss=0.5546 | acc=0.8370\n",
            "Epoch 15 | loss=0.5112 | acc=0.8535\n",
            "Test accuracy: 0.8545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fqvRv6_nns1j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}